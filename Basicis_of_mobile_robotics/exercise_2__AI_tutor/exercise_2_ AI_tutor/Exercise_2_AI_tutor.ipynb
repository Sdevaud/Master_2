{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ca3943",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T20:09:36.824740Z",
     "start_time": "2020-05-04T20:09:36.816919Z"
    }
   },
   "source": [
    "\n",
    "<div style=\"border:1px solid black; padding:20px 20px;text-align: justify;text-justify: inter-word\">\n",
    "    <strong>Exercise Session 2 - *PART 1* (over 2) - Computer vision: Hough Tranform <br/> Duration : 2 hours in session (PART 2 will be given separetely [basics of computer vision] and can be started during the session and at home) </strong><br/><br/>\n",
    "    <span style=\"text-decoration:underline;font-weight:bold;\">How to use this notebook?</span><br/>\n",
    "    This notebook is made of text cells and code cells. The code cells have to be <strong>executed</strong> to see the result of the program. To execute a cell, simply select it and click on the \"play\" button (<span style=\"font: bold 12px/30px Arial, serif;\">&#9658;</span>) in the tool bar just above the notebook, or type <code>shift + enter</code>. It is important to execute the code cells in their order of appearance in the notebook.<br/>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "- Please use code for any calculations \n",
    "- Feel free to use <strong>markdown</strong> or Raw NBConvert cells for your notes. </div>\n",
    "\n",
    "**Note**: The images used in this session are from online tutorials. While references are left out to avoid giving away answers, make sure to cite your sources properly in your project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8916c9a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-23T13:14:16.519011Z",
     "start_time": "2021-09-23T13:14:14.397804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: tqdm in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (3.10.6)\n",
      "Requirement already satisfied: numpy in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (2.2.6)\n",
      "Requirement already satisfied: ipywidgets in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (8.1.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (4.59.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (3.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipywidgets) (9.5.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\n",
      "Requirement already satisfied: stack_data in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/seby/miniconda3/envs/mondada/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "#installations\n",
    "!pip install opencv-python tqdm matplotlib numpy ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438e8c6",
   "metadata": {},
   "source": [
    "---\n",
    "# Instruction for experiment AI Tutor: \n",
    "While completing this notebook, you'll have the opportunity to use AI tutor. Here you can access to it: **https://graphsearch.epfl.ch/en/chatbot?model=MICRO-452-tutor** if you consent to particpate to the experiment. Please **exclusively use this language model** for all tasks for today (not copilot, chatGPT, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6930843",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95937568",
   "metadata": {},
   "source": [
    "# Implementing the Hough Transform to Identify Straight Lines in an Image\n",
    "\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "The goal of this exercise is going to be to code the Hough transform to identify straight lines in an image. We are going to use the following image throughout the exercise in order to test the different steps. The image is located in the Images folder under ``pentagon.png``\n",
    "\n",
    "As this is one of your first \"big\" coding exercises we are going to guide you through it.\n",
    "\n",
    "\n",
    "\n",
    "![Pentagon](images/pentagon.png)\n",
    "\n",
    "\n",
    "## Importing the libraries \n",
    "\n",
    "We are going to need the :\n",
    "\n",
    "- `opencv` for image processing (software library that provides a comprehensive set of tools for computer vision tasks. It's widely used in applications ranging from real-time video processing to advanced robotics.)\n",
    "\n",
    "- `math` for the trigonometry functions\n",
    "\n",
    "- `numpy` for array processing\n",
    "\n",
    "- `matplotlib` for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f38ecbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:02:38.201766Z",
     "start_time": "2020-09-22T14:02:38.198782Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:35.180722Z",
     "iopub.status.busy": "2024-09-16T10:35:35.180044Z",
     "iopub.status.idle": "2024-09-16T10:35:35.745810Z",
     "shell.execute_reply": "2024-09-16T10:35:35.745415Z",
     "shell.execute_reply.started": "2024-09-16T10:35:35.180698Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5305ee6",
   "metadata": {},
   "source": [
    "## Loading and displaying the image\n",
    "### Importing OpenCV, Reading and Displaying an Image\n",
    "OpenCV<sup id=\"a1\">[1](#f1)</sup> is a software library that provides a comprehensive set of tools for image processing and computer vision tasks. It's widely used in applications ranging from real-time video processing to advanced robotics.\n",
    "\n",
    "Start by giving the filename with the full path so that the mpimg module can load the image with the imread function. \n",
    "\n",
    "Then display the image object with plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b9d3f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:02:38.432427Z",
     "start_time": "2020-09-22T14:02:38.205044Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:36.489734Z",
     "iopub.status.busy": "2024-09-16T10:35:36.488694Z",
     "iopub.status.idle": "2024-09-16T10:35:36.586045Z",
     "shell.execute_reply": "2024-09-16T10:35:36.585608Z",
     "shell.execute_reply.started": "2024-09-16T10:35:36.489684Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@25.220] global loadsave.cpp:275 findDecoder imread_('images/pentagon.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Image data of dtype object cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m filename = \u001b[33m'\u001b[39m\u001b[33mimages/pentagon.png\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mondada/lib/python3.12/site-packages/matplotlib/pyplot.py:3601\u001b[39m, in \u001b[36mimshow\u001b[39m\u001b[34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[39m\n\u001b[32m   3579\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.imshow)\n\u001b[32m   3580\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mimshow\u001b[39m(\n\u001b[32m   3581\u001b[39m     X: ArrayLike | PIL.Image.Image,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3599\u001b[39m     **kwargs,\n\u001b[32m   3600\u001b[39m ) -> AxesImage:\n\u001b[32m-> \u001b[39m\u001b[32m3601\u001b[39m     __ret = \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m        \u001b[49m\u001b[43maspect\u001b[49m\u001b[43m=\u001b[49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolorizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m=\u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3621\u001b[39m     sci(__ret)\n\u001b[32m   3622\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mondada/lib/python3.12/site-packages/matplotlib/__init__.py:1524\u001b[39m, in \u001b[36m_preprocess_data.<locals>.inner\u001b[39m\u001b[34m(ax, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1521\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(ax, *args, data=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1524\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1525\u001b[39m \u001b[43m            \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1526\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1527\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbook\u001b[49m\u001b[43m.\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1529\u001b[39m     bound = new_sig.bind(ax, *args, **kwargs)\n\u001b[32m   1530\u001b[39m     auto_label = (bound.arguments.get(label_namer)\n\u001b[32m   1531\u001b[39m                   \u001b[38;5;129;01mor\u001b[39;00m bound.kwargs.get(label_namer))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mondada/lib/python3.12/site-packages/matplotlib/axes/_axes.py:5982\u001b[39m, in \u001b[36mAxes.imshow\u001b[39m\u001b[34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, colorizer, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[39m\n\u001b[32m   5979\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m aspect \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5980\u001b[39m     \u001b[38;5;28mself\u001b[39m.set_aspect(aspect)\n\u001b[32m-> \u001b[39m\u001b[32m5982\u001b[39m \u001b[43mim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5983\u001b[39m im.set_alpha(alpha)\n\u001b[32m   5984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m im.get_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5985\u001b[39m     \u001b[38;5;66;03m# image does not already have clipping set, clip to Axes patch\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mondada/lib/python3.12/site-packages/matplotlib/image.py:685\u001b[39m, in \u001b[36m_ImageBase.set_data\u001b[39m\u001b[34m(self, A)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(A, PIL.Image.Image):\n\u001b[32m    684\u001b[39m     A = pil_to_array(A)  \u001b[38;5;66;03m# Needed e.g. to apply png palette.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m \u001b[38;5;28mself\u001b[39m._A = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_image_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[38;5;28mself\u001b[39m._imcache = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    687\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/mondada/lib/python3.12/site-packages/matplotlib/image.py:648\u001b[39m, in \u001b[36m_ImageBase._normalize_image_array\u001b[39m\u001b[34m(A)\u001b[39m\n\u001b[32m    646\u001b[39m A = cbook.safe_masked_invalid(A, copy=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    647\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.dtype != np.uint8 \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.can_cast(A.dtype, \u001b[38;5;28mfloat\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msame_kind\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mImage data of dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mA.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m cannot be \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconverted to float\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    650\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m A.ndim == \u001b[32m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m A.shape[-\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m:\n\u001b[32m    651\u001b[39m     A = A.squeeze(-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# If just (M, N, 1), assume scalar and apply colormap.\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: Image data of dtype object cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'images/pentagon.png'\n",
    "img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e347b2af",
   "metadata": {},
   "source": [
    "## Creating the hough transform matrix\n",
    "\n",
    "1. We start by creating a numpy array of arbitrary dimensions. \n",
    "\n",
    "--> create the hough transform matrix (filled with zeros), called **_hough_space_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b73cd7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-22T14:02:38.436611Z",
     "start_time": "2020-09-22T14:02:38.434168Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:37.733856Z",
     "iopub.status.busy": "2024-09-16T10:35:37.733063Z",
     "iopub.status.idle": "2024-09-16T10:35:37.739599Z",
     "shell.execute_reply": "2024-09-16T10:35:37.738850Z",
     "shell.execute_reply.started": "2024-09-16T10:35:37.733802Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We choose to have a final matrix of the following\n",
    "# dimensions. This is an arbitrary decision\n",
    "\n",
    "r_dim = 200 \n",
    "theta_dim = 300\n",
    "\n",
    "#code here\n",
    "hough_space = np.zeros((r_dim, theta_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f480ebf8",
   "metadata": {},
   "source": [
    "2. Now we need to relate the dimensions of this new matrix to the corresponding values along the rho and theta axes. This means we need to determine the minimum and maximum values of theta and rho. \n",
    "\n",
    "--> Find the values of **theta min** and **theta max**\n",
    "\n",
    "\n",
    "--> From the image shape, determine **rho min** and **rho max**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46466b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#code here\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Image shape \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m height, width = \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m[:\u001b[32m2\u001b[39m]\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Theta axis\u001b[39;00m\n\u001b[32m      7\u001b[39m theta_min = \u001b[32m0\u001b[39m\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#code here\n",
    "\n",
    "# Image shape \n",
    "height, width = img.shape[:2]\n",
    "\n",
    "# Theta axis\n",
    "theta_min = 0\n",
    "theta_max = np.pi\n",
    "\n",
    "# Rho axis\n",
    "r_max = int(np.ceil(np.sqrt(height**2 + width**2)))\n",
    "r_min = -r_max"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ed82b6",
   "metadata": {},
   "source": [
    "Now we are going to compute the hough transform of the original image. The pseudo code is the following :\n",
    "\n",
    "    for all pixels:\n",
    "        if the pixel is white:\n",
    "              do nothing\n",
    "        else:\n",
    "            for theta values :\n",
    "                compute rho from the pixel coordinates and theta\n",
    "                normalise rho \n",
    "                update the hough space matrix for the theta and rho coordinates in the array\n",
    "                \n",
    "You should get a result similar to this one \n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/houghTransform.png)\n",
    "\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6faa8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:38.717931Z",
     "iopub.status.busy": "2024-09-16T10:35:38.716999Z",
     "iopub.status.idle": "2024-09-16T10:35:38.723454Z",
     "shell.execute_reply": "2024-09-16T10:35:38.722245Z",
     "shell.execute_reply.started": "2024-09-16T10:35:38.717879Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#code here\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mheight\u001b[49m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(width):\n\u001b[32m      4\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m img[y, x] > \u001b[32m0\u001b[39m : \n",
      "\u001b[31mNameError\u001b[39m: name 'height' is not defined"
     ]
    }
   ],
   "source": [
    "#code here\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        if img[y, x] > 0 : \n",
    "            for theta_idx in range(theta_dim):\n",
    "                theta = theta_min + (theta_max - theta_min) * theta_idx / theta_dim\n",
    "                r = int(x * np.cos(theta) + y * np.sin(theta))\n",
    "                r_idx = int((r - r_min) * r_dim / (r_max - r_min))\n",
    "                if 0 <= r_idx < r_dim:\n",
    "                    hough_space[r_idx, theta_idx] += 1\n",
    "\n",
    "plt.imshow(hough_space, aspect='auto', extent=(theta_min, theta_max, r_max, r_min))\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca78580",
   "metadata": {},
   "source": [
    "## Identifying the maxima of the Hough Transform\n",
    "\n",
    "After calculating the Hough space, the next step is to find the local extrema. This will give us the rho and theta parameters of the different straight lines in the image. \n",
    "\n",
    "To find the extrema, we will do the following :\n",
    "\n",
    "1. isolate the brightest spots\n",
    "\n",
    "2. enlarge the size of the spots\n",
    "\n",
    "3. find the centroid of the spots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22468e82",
   "metadata": {},
   "source": [
    "### Isolating the brightest spots through thresholding\n",
    "\n",
    "To isolate the bright spots and remove the gradients around the maxima we are going to apply **thresholding** to convert the image into 0's for the dark areas and 1's around the maximas. Have a look [here](https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html) at the different thresholding functions that opencv has to offer. \n",
    "\n",
    "Play with the parameters to try to obtain an image similar to this one \n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/thresholding_output.png)\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338758b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:40:20.301138Z",
     "start_time": "2020-05-05T15:40:20.056494Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:39.521943Z",
     "iopub.status.busy": "2024-09-16T10:35:39.520957Z",
     "iopub.status.idle": "2024-09-16T10:35:39.527475Z",
     "shell.execute_reply": "2024-09-16T10:35:39.526300Z",
     "shell.execute_reply.started": "2024-09-16T10:35:39.521888Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842b4501",
   "metadata": {},
   "source": [
    "### Enlarging the size of the spots through morphological operators\n",
    "\n",
    "To identify the location of the local maxima, we will make use of find contours. However the spots in the image are too small to apply the opencv functions. That is why we are going to start by increasing their size through morphological operations. Have a look [here](https://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html) to see the different operators and their effect on a binary image. \n",
    "\n",
    "\n",
    "You should get an image like this one : \n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/morphological_output.png)\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec215ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:40:20.547095Z",
     "start_time": "2020-05-05T15:40:20.304135Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:40.050449Z",
     "iopub.status.busy": "2024-09-16T10:35:40.049636Z",
     "iopub.status.idle": "2024-09-16T10:35:40.056424Z",
     "shell.execute_reply": "2024-09-16T10:35:40.054982Z",
     "shell.execute_reply.started": "2024-09-16T10:35:40.050405Z"
    }
   },
   "outputs": [],
   "source": [
    "#code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be3f04c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-04T22:18:47.171768Z",
     "start_time": "2020-05-04T22:18:47.005549Z"
    }
   },
   "source": [
    "### Identifying the Centroids' Locations Through Contours \n",
    "\n",
    "Now we have bigger spots and we are going to use Opencv's built in functions to find the contours and deduce the location of the centroid in the hough space. [An example is provided here](https://www.learnopencv.com/find-center-of-blob-centroid-using-opencv-cpp-python/). \n",
    "\n",
    "You should get a result similar to this one : \n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](Images/centroid_output.png)\n",
    "\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e8020",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T15:40:20.790040Z",
     "start_time": "2020-05-05T15:40:20.548963Z"
    },
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:40.985046Z",
     "iopub.status.busy": "2024-09-16T10:35:40.984215Z",
     "iopub.status.idle": "2024-09-16T10:35:40.991066Z",
     "shell.execute_reply": "2024-09-16T10:35:40.989497Z",
     "shell.execute_reply.started": "2024-09-16T10:35:40.984979Z"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fe241f",
   "metadata": {},
   "source": [
    "## Computing the location of the straight lines in the original image and drawing them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b83bd8",
   "metadata": {},
   "source": [
    "With the maxima obtained, we can now compute the corresponding segments in the original image. You should get a result similar to this one. \n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "![Pentagon](images/hough_transform.png)\n",
    "\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5a1650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T10:35:42.782868Z",
     "iopub.status.busy": "2024-09-16T10:35:42.782142Z",
     "iopub.status.idle": "2024-09-16T10:35:42.787101Z",
     "shell.execute_reply": "2024-09-16T10:35:42.785802Z",
     "shell.execute_reply.started": "2024-09-16T10:35:42.782820Z"
    }
   },
   "outputs": [],
   "source": [
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713e3fd",
   "metadata": {},
   "source": [
    "> Note that the overall exercise was inspired from the example [here](https://www.science-emergence.com/Articles/Implementing-a-simple-python-code-to-detect-straight-lines-using-Hough-transform/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4d1ec",
   "metadata": {},
   "source": [
    "---\n",
    "<span style=\"color:green\">\n",
    "\n",
    "## Please come back to the questionnaire (survey)\n",
    "    \n",
    "Come back to the webpage where you have the questionnaire and upload:\n",
    "\n",
    "(Even if Incomplete, Please Submit 🙏🏼)\n",
    "- This juypter notebook <code>Exercise_2_AI_tutor.ipynb<code>\n",
    "</span>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9b08d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "mondada",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "unianalytics_cell_mapping": [
   [
    "35ca3943",
    "35ca3943"
   ],
   [
    "8916c9a7",
    "8916c9a7"
   ],
   [
    "4066f4b6",
    "4066f4b6"
   ],
   [
    "2438e8c6",
    "2438e8c6"
   ],
   [
    "833c84d6",
    "833c84d6"
   ],
   [
    "812b095d",
    "812b095d"
   ],
   [
    "3c764a72",
    "3c764a72"
   ],
   [
    "d6930843",
    "d6930843"
   ],
   [
    "95937568",
    "95937568"
   ],
   [
    "1f38ecbc",
    "1f38ecbc"
   ],
   [
    "d5305ee6",
    "d5305ee6"
   ],
   [
    "c7b9d3f2",
    "c7b9d3f2"
   ],
   [
    "e347b2af",
    "e347b2af"
   ],
   [
    "12e92c5d",
    "12e92c5d"
   ],
   [
    "3b73cd7f",
    "3b73cd7f"
   ],
   [
    "f480ebf8",
    "f480ebf8"
   ],
   [
    "0570b9d3",
    "0570b9d3"
   ],
   [
    "71ed82b6",
    "71ed82b6"
   ],
   [
    "8c6faa8b",
    "8c6faa8b"
   ],
   [
    "a83b7dd7",
    "a83b7dd7"
   ],
   [
    "bca78580",
    "bca78580"
   ],
   [
    "22468e82",
    "22468e82"
   ],
   [
    "338758b0",
    "338758b0"
   ],
   [
    "a4a6a80d",
    "a4a6a80d"
   ],
   [
    "842b4501",
    "842b4501"
   ],
   [
    "ec215ec4",
    "ec215ec4"
   ],
   [
    "0089c4b2",
    "0089c4b2"
   ],
   [
    "0be3f04c",
    "0be3f04c"
   ],
   [
    "dc1e8020",
    "dc1e8020"
   ],
   [
    "cd682f5b",
    "cd682f5b"
   ],
   [
    "c4fe241f",
    "c4fe241f"
   ],
   [
    "44b83bd8",
    "44b83bd8"
   ],
   [
    "2f5a1650",
    "2f5a1650"
   ],
   [
    "a713e3fd",
    "a713e3fd"
   ],
   [
    "d0d4d1ec",
    "d0d4d1ec"
   ],
   [
    "f6d9b08d",
    "f6d9b08d"
   ]
  ],
  "unianalytics_notebook_id": "c42852b7-93c7-4dfb-a629-3ee6d0a69866"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
