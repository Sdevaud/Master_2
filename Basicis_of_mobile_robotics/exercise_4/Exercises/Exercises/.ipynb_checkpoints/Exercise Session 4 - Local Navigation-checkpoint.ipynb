{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border:1px solid black; padding:20px 20px;text-align: justify;text-justify: inter-word\">\n",
    "    <strong>Exercise Session 4 - Local Navigation<br/> Duration : 4 hours (2 in session + 2 at home)</strong><br/><br/>\n",
    "    <span style=\"text-decoration:underline;font-weight:bold;\">How to use this notebook?</span><br/>\n",
    "    This notebook is made of text cells and code cells. The code cells have to be <strong>executed</strong> to see the result of the program. To execute a cell, simply select it and click on the \"play\" button (<span style=\"font: bold 12px/30px Arial, serif;\">&#9658;</span>) in the tool bar just above the notebook, or type <code>shift + enter</code>. It is important to execute the code cells in their order of appearance in the notebook.<br/>\n",
    "You can make use of the table of contents to navigate easily between sections.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"justify;text-justify: inter-word\">\n",
    "So that you may familiarise with the notebooks and the basic python syntax, the exercises are provided in notebook form and whenever there are any calculations to be made, we encourage you to do them by code. Also, if you want to take notes, we encourage you to use the markdown or Raw NBConvert cells. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Goals\" data-toc-modified-id=\"Learning-Goals-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning Goals</a></span></li><li><span><a href=\"#Requirements\" data-toc-modified-id=\"Requirements-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Requirements</a></span></li><li><span><a href=\"#Proximity-Sensors\" data-toc-modified-id=\"Proximity-Sensors-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Proximity Sensors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Characterising-the-Proximity-Sensors\" data-toc-modified-id=\"Characterising-the-Proximity-Sensors-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Characterising the Proximity Sensors</a></span></li></ul></li><li><span><a href=\"#Local-Navigation-on-Thymio\" data-toc-modified-id=\"Local-Navigation-on-Thymio-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Local Navigation on Thymio</a></span><ul class=\"toc-item\"><li><span><a href=\"#Reminder:-Control-your-Thymio-using-tdmclient\" data-toc-modified-id=\"Reminder:-Control-your-Thymio-using-tdmclient-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Reminder: Control your Thymio using tdmclient</a></span></li><li><span><a href=\"#Moving-Toward-the-Goal\" data-toc-modified-id=\"Moving-Toward-the-Goal-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Moving Toward the Goal</a></span></li><li><span><a href=\"#Local-Obstacle-Avoidance\" data-toc-modified-id=\"Local-Obstacle-Avoidance-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Local Obstacle Avoidance</a></span></li><li><span><a href=\"#Potential-Field-Navigation\" data-toc-modified-id=\"Potential-Field-Navigation-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Potential Field Navigation</a></span></li></ul></li><li><span><a href=\"#(Optional)-Using-Sensor-Values-and-Displacements-to-Map-the-Environment\" data-toc-modified-id=\"(Optional)-Using-Sensor-Values-and-Displacements-to-Map-the-Environment-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>(Optional) Using Sensor Values and Displacements to Map the Environment</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-local-occupancy-grid-based-on-the-individual-sensor-values\" data-toc-modified-id=\"Creating-a-local-occupancy-grid-based-on-the-individual-sensor-values-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Creating a local occupancy grid based on the individual sensor values</a></span></li><li><span><a href=\"#Creating-the-global-map-provided-the-sensor-values-and-robot-displacements-within-the-map.\" data-toc-modified-id=\"Creating-the-global-map-provided-the-sensor-values-and-robot-displacements-within-the-map.-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Creating the global map provided the sensor values and robot displacements within the map.</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Learning Goals\n",
    "\n",
    "\n",
    "- Proximity sensor analysis and local navigation implementation on Thymio\n",
    "\n",
    "\n",
    "- Analysing the proximity sensors\n",
    "\n",
    "\n",
    "- Creating a local occupancy grid and global map from sensor values and displacements (Jupyter notebooks)\n",
    "\n",
    "\n",
    "- Implementing local navigation on the Thymio  (ASEBA studio) in real time\n",
    "\n",
    "\n",
    "# Requirements\n",
    "\n",
    "- Thymio \n",
    "\n",
    "- The gradient printed on an A3 paper\n",
    "\n",
    "\n",
    "![gradient](images/gradient.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade tdmclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proximity Sensors\n",
    "\n",
    "## Characterising the Proximity Sensors\n",
    "\n",
    "Proximity sensors just measure the presence of objects, and are hard to characterise in that very fuzzy function. Consider here the use of proximity sensors as distance sensors for a very well defined situation (facing a white paper). \n",
    "\n",
    "\n",
    "\n",
    "***In this context, is it possible to extract the position from the data acquired by the proximity sensor?***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***If yes, define an approximate value of the range, the dynamic range, the update frequency, the precision, the resolution, and the accuracy of this specific distance sensor.***\n",
    "\n",
    "***Is there cross-talk between the sensors? How can you verify this?***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Navigation on Thymio\n",
    "\n",
    "\n",
    "Local navigation allows modulating the trajectory to avoid unforeseen, local obstacles. It pushes often the controller to leave the optimal path to make an avoidance manoeuvre. Once the obstacle is passed, the controller can go back to the optimal path or find a new one. An important issue is to decide when the controller has to start avoiding, and, more difficult, when the obstacle can be considered as passed.\n",
    "\n",
    "We will work with the Thymio placed on a surface that has a gray level gradient. We can consider that the darker spot is the goal. This allows, using the ground sensors, to measure the orientation to Â£the goal.\n",
    "\n",
    "\n",
    "For this exercise, you should make use of the ``gradient.pdf`` file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: Control your Thymio using tdmclient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week, we have seen how to execute a piece of code based on an event. We can also declare a specific frequency and use a timer. This could be useful for some parts of the exercises, to decide a sampling time and execute a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T09:35:07.792889Z",
     "start_time": "2021-09-08T09:35:05.310890Z"
    }
   },
   "outputs": [],
   "source": [
    "# Connect your Thymio, open Thymio Suite and then execute:\n",
    "import tdmclient.notebook\n",
    "await tdmclient.notebook.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T09:35:12.256831Z",
     "start_time": "2021-09-08T09:35:12.040762Z"
    }
   },
   "outputs": [],
   "source": [
    "%%run_python\n",
    "\n",
    "on = False\n",
    "timer_period[0] = 500\n",
    "@onevent\n",
    "def timer0():\n",
    "    global on, leds_top\n",
    "    on = not on\n",
    "    if on:\n",
    "        leds_top = [32, 32, 0]\n",
    "    else:\n",
    "        leds_top = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-08T09:36:01.565719Z",
     "start_time": "2021-09-08T09:36:01.333784Z"
    }
   },
   "outputs": [],
   "source": [
    "stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving Toward the Goal\n",
    "\n",
    "Implement on Thymio a program that makes it moving toward the goal, as illustrated in the figure below that shows for various positions the path that allows to go to the goal. For this, use the two ground sensors and a simple reactive behaviour.\n",
    "\n",
    "<br>\n",
    "\n",
    "![Filename](Images/gotogoal.png)\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Obstacle Avoidance\n",
    "\n",
    "Put an obstacle on the path, for instance the box of Thymio, as illustrated in the figure below. The Figure illustrates the paths that allow to go to the goal avoiding the obstacle. Implement a state machine with two states, one moving toward the goal like in the previous behaviour, another making obstacle avoidance. Which condition do you choose to decide to change from going toward the goal to obstacle avoidance behaviour? Which condition do you choose to decide to change back to moving toward the goal?\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "![Filename](Images/avoid.png)\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Potential Field Navigation\n",
    "\n",
    "Implement the local obstacle avoidance behaviour using the potential field approach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Using Sensor Values and Displacements to Map the Environment\n",
    "\n",
    "The goal of this exercise is two-fold:\n",
    "\n",
    "\n",
    "- to implement the local occupancy grid around the Thymio robot based on the sensor readings. \n",
    "\n",
    "\n",
    "- provided a set of displacements and sensor readings, estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:44.515686Z",
     "start_time": "2020-09-02T10:34:43.097986Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install numpy matplotlib pandas scipy tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a local occupancy grid based on the individual sensor values\n",
    "\n",
    "Obstacle avoidance algorithms rely on knowing where the obstacles in the environment are. \n",
    "The goal of this exercise is to determine the position of obstacles detected by a virtual Thymio's sensors and place them in a local occupancy grid. \n",
    "\n",
    "You will have to start by estimating the distance of the different obstacles in the environment using the proximity sensor measurements that are provided. \n",
    "\n",
    "Therefore, you need to convert the sensor values into distances and place them in the grid around the robot. As such, you must take into account the geometry of the robot and the position / orientation of the different sensors. \n",
    "\n",
    "\n",
    "------------------------------------------------------------------\n",
    "------------------------------------------------------------------\n",
    "First we start by loading some of the standard python libraries and others that we will use in the exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.332933Z",
     "start_time": "2020-09-02T10:34:44.518316Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "\n",
    "from local_occupancy import sensor_measurements, sensor_distances\n",
    "from local_occupancy import thymio_coords, sensor_pos_from_center, sensor_angles\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we are going to give you a list of : \n",
    "\n",
    "- fictional sensor values : `sensor_measurements`\n",
    "\n",
    "- corresponding distance measurements  : `sensor_distances`\n",
    "\n",
    "\n",
    "As we are going to be giving you quite a few variables in this exercise, we are giving you a function called **`variable_info`**. This function will print the type, content and elements that can be accessed from the variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.344696Z",
     "start_time": "2020-09-02T10:34:45.336851Z"
    }
   },
   "outputs": [],
   "source": [
    "def variable_info(variable):\n",
    "    \"\"\"\n",
    "    Provided a variable, prints the type and content of the variable\n",
    "    \"\"\"\n",
    "    print(\"This variable is a {}\".format(type(variable)))\n",
    "    if type(variable) == np.ndarray:\n",
    "        print(\"\\n\\nThe shape is {}\".format(variable.shape))\n",
    "    print(\"\\n\\nThe data contained in the variable is : \")\n",
    "    print(variable)\n",
    "    print(\"\\n\\nThe elements that can be accessed in the variable are :\\n\")\n",
    "    print(dir(variable))\n",
    "    \n",
    "variable_info(np.array([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start easy and plot the sensor_distances w.r.t the sensor measurements. Update the code block below to get the desired output. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.588587Z",
     "start_time": "2020-09-02T10:34:45.349080Z"
    }
   },
   "outputs": [],
   "source": [
    "x = [1, 2, 3, 4, 5, 6, 7]\n",
    "y = [8, 9, 10, 1, 2, 3, 4]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"x values\")\n",
    "plt.ylabel(\"y values\")\n",
    "plt.title(\"My plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the function below that will give you the distance of the different obstacles in the environment based on the proximity sensor measurements. Have a look at the `interp1d` function that scipy has to provide. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.594790Z",
     "start_time": "2020-09-02T10:34:45.590704Z"
    }
   },
   "outputs": [],
   "source": [
    "## Interpolation from sensor values to distances in cm\n",
    "def sensor_val_to_cm_dist(val):\n",
    "    \"\"\"\n",
    "    Returns the distance corresponding to the sensor value based \n",
    "    on the sensor characteristics\n",
    "    :param val: the sensor value that you want to convert to a distance\n",
    "    :return: corresponding distance in cm\n",
    "    \"\"\"\n",
    "    return val\n",
    "\n",
    "# Verifying the interpolation\n",
    "sensor_val_to_cm_dist(4996)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have verified that the function works, the goal is to create the local occupancy grid that takes into account the geometry of the robot. \n",
    "\n",
    "This means, we would like it if you plotted the position of the obstacles in the grid surrounding the robot. For this you need the following information :\n",
    "\n",
    "- The position of each sensor with respect to the center of the robot. This is provided in the variable `sensor_pos_from_center` : a list containing the coordinates of the 7 sensors proximity sensors starting from the top left to the bottom left in clockwise direction. (0,0) corresponds to the center of the robot\n",
    "\n",
    "- The orientation of each of the sensors, provided under `sensor_angles` : a list containing the angle that each sensor does with respect to the x axis. \n",
    "\n",
    "- The position of the comtour of the robot w.r.t its center, provided under `thymio_coords`, for the visualisation of the occupancy grid: a list of coordinates making up the outline of the Thymio robot. (0,0) corresponds to the center of the robot. \n",
    "\n",
    "\n",
    "We have provided the prototype of the function and of the plots below. Please update it to get the results shown in the image below with the sensor values provided in the code cell. \n",
    "\n",
    "<img src=\"Images/part1_solution.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.809526Z",
     "start_time": "2020-09-02T10:34:45.596506Z"
    }
   },
   "outputs": [],
   "source": [
    "def obstacles_pos_from_sensor_vals(sensor_vals):\n",
    "    \"\"\"\n",
    "    Returns a list containing the position of the obstacles\n",
    "    w.r.t the center of the Thymio robot. \n",
    "    :param sensor_vals: sensor values provided clockwise starting from the top left sensor.\n",
    "    :return: numpy.array() that contains the position of the different obstacles\n",
    "    \"\"\"\n",
    "    obstacle_positions = [[0,0] for i in range(len(sensor_vals))] #DUMMY VALUES\n",
    "    \n",
    "    return np.array(obstacle_positions)\n",
    "\n",
    "sensor_vals = [1400, 3000, 5000, 500, 0, 5000, 1400]\n",
    "\n",
    "obstacles_pos = obstacles_pos_from_sensor_vals(sensor_vals)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"My title\")\n",
    "plt.xlabel(\"x label\")\n",
    "plt.ylabel(\"y label\")\n",
    "plt.plot(thymio_coords[:,0], thymio_coords[:,1])\n",
    "plt.axis(\"equal\")\n",
    "plt.scatter(obstacles_pos[:,0], obstacles_pos[:,1], marker=\"o\", color=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Creating the global map provided the sensor values and robot displacements within the map.\n",
    "\n",
    "Now that you are able to construct the local occupancy grid, the goal is to remember where the obstacles are and create a global map. Here, we give you a set of relative displacements (`rel_dpos`) and corresponding sensor values (`map_sensor_vals`). \n",
    "\n",
    "The goal is that you use this information to construct the global map. \n",
    "\n",
    "\n",
    "\n",
    "Let's start by constructing a function that rotates a set of coordinates by the given angle. You can test it out on the drawing of the thymio's coordinates to make sure it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.813829Z",
     "start_time": "2020-09-02T10:34:45.811230Z"
    }
   },
   "outputs": [],
   "source": [
    "def rotate(angle, coords):\n",
    "    \"\"\"\n",
    "    Rotates the coordinates of a matrix by the desired angle\n",
    "    :param angle: angle in radians by which we want to rotate\n",
    "    :return: numpy.array() that contains rotated coordinates\n",
    "    \"\"\"\n",
    "    \n",
    "    return coords #DUMMY VALUE\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have done that, we can move on to constructing a global map from the relative displacements and corresponding sensor values. \n",
    "\n",
    "------\n",
    "------\n",
    "One way of solving this problem is to do the following (but it is not the only way so if you prefer adopting another solution or changing any portion of the pseudo-code feel free to do so) :\n",
    "\n",
    "1. Start by defining the initial position of the robot as the origin of the map (i.e the position x,y,theta = 0, 0, 0)\n",
    "\n",
    "\n",
    "2. Provided the relative displacements (rel_dpos), compute the absolute position of the robot at each step\n",
    "\n",
    "\n",
    "3. Compute the local occupancy grid from the sensor values at each step. Use the function that you implemented previously\n",
    "\n",
    "\n",
    "4. Create the global map from the local occupancy grids by rotating and translating the obstacles found. To do so, for each data point you will have to :\n",
    "    - Rotate the local occupancy grid and coordinates of the outline of the thymio\n",
    "    - Translate the local occupancy grid and the coordinates of the outline to the position of the Thymio\n",
    "    - Store the coordinates in a list\n",
    "\n",
    "5. Plot on a final figure :\n",
    "    - the trajectory taken by the robot\n",
    "    - the outline of the robot at each step\n",
    "    - the position of the obstacles that were seen by the robot in the global frame\n",
    "\n",
    "-----\n",
    "-----\n",
    "\n",
    "Here is the result you should get : \n",
    "\n",
    "<img src=\"Images/map_creation_solution.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "-----\n",
    "Below is a skeleton which will guide you through the pseudo-code above, but feel free to modify any portion to suit your needs. \n",
    "\n",
    "**Steps 1 and 2 : compute the absolute position of the robot at each step**\n",
    "\n",
    "Let's start by printing the content of the rel_dpos variable which provides the relative displacement at each step. Knowing the content of this variable will help you estimate whether your absolute positions are correct. Of course you could always just compare the plot with the image provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.821355Z",
     "start_time": "2020-09-02T10:34:45.816958Z"
    }
   },
   "outputs": [],
   "source": [
    "from local_occupancy import map_sensor_vals, rel_dpos\n",
    "\n",
    "variable_info(rel_dpos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.825757Z",
     "start_time": "2020-09-02T10:34:45.823552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Arbitrarily define the initial robot position as the origin of \n",
    "# the map\n",
    "\n",
    "\n",
    "# Provided the relative positions, compute the absolute positions \n",
    "# at each step\n",
    "\n",
    "\n",
    "# Plot the absolute positions and make sure they are coherent with \n",
    "# the displacements\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3 : Compute the local occupancy grids for each set of measurements provided**\n",
    "\n",
    "Compute the list of local occupancy grids at each position. For this, you will need the `map_sensor_vals` variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.830587Z",
     "start_time": "2020-09-02T10:34:45.827783Z"
    }
   },
   "outputs": [],
   "source": [
    "variable_info(map_sensor_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T10:34:45.834991Z",
     "start_time": "2020-09-02T10:34:45.832669Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the local occupancy grid from the sensor values at each step\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps 4 and 5 : Create the global map from the local occupancy grids by rotating and translating the obstacles found and visualise the result**\n",
    "\n",
    "Hint : to rotate obstacles try to think back to the rotation matrices you saw in the basics of robotics course. If you have forgotten or not seen them the principle is pretty simple and can be found [here](https://en.wikipedia.org/wiki/Rotation_matrix). To do the dot product, one [function provided by numpy could be helpful](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
