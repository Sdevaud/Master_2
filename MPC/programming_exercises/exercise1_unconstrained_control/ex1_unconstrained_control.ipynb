{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d7ab33c",
   "metadata": {},
   "source": [
    "<small>\n",
    "Copyright (C) 2025, École Polytechnique Fédérale de Lausanne. All Rights Reserved.\n",
    "</small>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9dc310",
   "metadata": {},
   "source": [
    "# Model Predictive Control: Exercise 1\n",
    "\n",
    "Consider the discrete-time LTI system defined by\n",
    "$$\n",
    "\\begin{align*}\n",
    "x_{i+1} &= Ax_i + Bu_i \\\\\n",
    "y_i &= Cx_i\n",
    "\\end{align*}\n",
    "$$\n",
    "with\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "4/3 & -2/3 \\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}, \\quad\n",
    "B = \\begin{bmatrix}\n",
    "1 \\\\\n",
    "0\n",
    "\\end{bmatrix}, \\quad\n",
    "C = \\begin{bmatrix}\n",
    "-2/3 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74c385ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import control as ct\n",
    "\n",
    "# System dynamics\n",
    "nx = 2\n",
    "nu = 1\n",
    "A = np.array([[4 / 3, -2 / 3], [1, 0]])\n",
    "B = np.array([[1], [0]])\n",
    "C = np.array([[-2 / 3, 1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cac4c5",
   "metadata": {},
   "source": [
    "Throughout this notebook, you will mainly use `numpy` and `matplolib`. If you are not familiar with these libraries, we encourage you to check out some basic guides such as the following ones:\n",
    "- [NumPy for Matlab users](https://numpy.org/doc/stable/user/numpy-for-matlab-users.html): a good starting point for people familiar with Matlab. You will see that NumPy and Matlab resemble each other but do have some differences.\n",
    "- [NumPy fundamentals](https://numpy.org/doc/stable/user/basics.html): a more exhaustive guide that can be a useful resource beyond this course. You should not feel obligated to read all of it at once. We recommend rather going there to complement your knowledge on a specific topic when you need it.\n",
    "- [Basic Matplotlib](https://www.w3schools.com/python/matplotlib_intro.asp): simple examples to show you the basic functionality of Matplotlib. If you are used to Matlab plotting\n",
    "\n",
    "Note that all the functions you should need are already imported at the beginning of this notebook, you can use them directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2c5e75",
   "metadata": {},
   "source": [
    "## Problem 1: Bellman recursion\n",
    "\n",
    "Consider the optimal control law minimizing the cost\n",
    "$$ V = \\sum_{i=0}^{N-1} (x_i^T Q x_i + u_i^T R u_i) + x_N^T P_f x_N$$\n",
    "with \n",
    "$$ Q = C^T C + 0.001 I_{2\\times 2}, \\quad R = 0.001, \\quad P_f = Q\\,.$$\n",
    "\n",
    "### Task 1\n",
    "\n",
    "Use the discrete-time Bellman recursion to define a function `bellman` that takes as input an integer `N` and outputs a list of arrays `Klist` containing the linear feedback gains to be applied at each stage `i` in the finite horizon.\n",
    "\n",
    "> _Hint_: You can use the function `np.linalg.solve` to solve a linear system, the same way you would use `\\` in Matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10373ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = C.T @ C + 0.001 * np.eye(2)\n",
    "R = np.array([[0.001]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cef4935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman(N: int)-> list[np.ndarray]:\n",
    "    # TODO: implement the Bellman recursion here\n",
    "    # control gain matrices\n",
    "    Klist = []\n",
    "\n",
    "    # Bellman/Riccati recursion\n",
    "    H = Q\n",
    "    for i in range(N - 1, -1, -1):\n",
    "        # K = -(R + B.T @ H @ B) @ np.linalg.inv(B.T @ H @ A)\n",
    "        K = -np.linalg.solve(R + B.T @ H @ B, B.T @ H @ A)\n",
    "        H = Q + K.T @ R @ K + (A + B @ K).T @ H @ (A + B @ K)\n",
    "\n",
    "        # Store the complete time-varying feedback law\n",
    "        # (necessary to later plot the predictions)\n",
    "        Klist.append(K)\n",
    "\n",
    "    Klist = Klist[::-1]\n",
    "    return Klist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197abb52",
   "metadata": {},
   "source": [
    "# Problem 2: Receding horizon control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe2e231",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Compute the open-loop prediction given by the optimal control law computed you computed above at the state $x=[10, 10]^T$. Compute the closed-loop state trajectory over 20 time steps, starting from the same initial state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial condition\n",
    "x0 = np.array([[10], [10]])\n",
    "\n",
    "# Control gains\n",
    "N = 20 # TODO: choose a horizon length\n",
    "Klist = bellman(N)\n",
    "\n",
    "# Open-loop prediction\n",
    "x_ol = [x0] # TODO: construct the list of states for the open-loop predictions using a for loop\n",
    "for i in range(N):\n",
    "    u = Klist[i] @ x_ol[-1]\n",
    "    x_ol.append(A @ x_ol[-1] + B @ u)\n",
    "x_ol = np.column_stack(x_ol)\n",
    "\n",
    "# Closed-loop control simulation\n",
    "K = Klist[0]\n",
    "# Checking if CL system is stable\n",
    "if np.max(np.abs(np.linalg.eigvals(A + B @ K))) > 1:\n",
    "    raise ValueError(\"System is unstable! Choose a longer horizon.\")\n",
    "tmax = 20\n",
    "\n",
    "x_cl = [x0] # TODO: construct the list of states for the closed-loop predictions using a for loop\n",
    "\n",
    "for _ in range(1, tmax + 1):\n",
    "    # Always apply the first controller gain\n",
    "    # (\"receding horizon fashion\")\n",
    "    u = K @ x_cl[-1]\n",
    "\n",
    "    x_cl.append(A @ x_cl[-1] + B @ u)\n",
    "\n",
    "x_cl = np.column_stack(x_cl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f669c8b",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Plot side by side the closed-loop trajectory and the open-loop prediction obtained from the first state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b29e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the open-loop and closed-loop trajectories here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c870a6",
   "metadata": {},
   "source": [
    "> **NOTE**:\n",
    "> In the following three tasks, you should only modify some values in the code above, observe the results and make conclusions.\n",
    "\n",
    "### Task 3\n",
    "\n",
    "Use the code for the previous two questions to find the minimum horizon length $N^*$ that stabilizes the system.\n",
    "\n",
    "### Task 4\n",
    "\n",
    "Motivate why increasing the horizon stablizes the closed-loop system.\n",
    "\n",
    "### Task 5\n",
    "\n",
    "Given a horizon length $N^*$ that stabilizes the closed-loop system, can you be sure that the system will be stable for $N > N^*$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d5387",
   "metadata": {},
   "source": [
    "# Problem 3: Linear Quadratic Regulator (LQR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef9ea6f",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "\n",
    "Implement the infinite horizon LQR controller $u = K_\\infty x$.\n",
    "\n",
    "> _Hint_: You can use the function [`dlqr`](https://python-control.readthedocs.io/en/0.10.2/generated/control.dlqr.html#control.dlqr) from the Python control toolbox (imported above). Note that this function uses a slightly different convention and computes a matrix $K_\\infty$ such that the control to apply is $u = -K_\\infty x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955d72e7",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "\n",
    "Compare the infinite horizon cost for the system in closed loop with $u = K_\\infty x$ and with $u = K_{N^*} x$.\n",
    "\n",
    "> _Hint_: For the latter, you can approximate the infinite horizon cost numerically using long state and input trajectories:\n",
    "> $$\n",
    "> V_\\infty = \\sum_{k=0}^{\\infty} (x_k^T Q x_k + u_k^T R u_k) \\approx \\sum_{k=0}^{1000} (x_k^T Q x_k + u_k^T R u_k) \n",
    "> $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3026a607",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_inf = ... # compute the infinite horizon cost here\n",
    "print(\"Infinite horizon cost with u = Kinf @ x :\", cost_inf)\n",
    "\n",
    "cost_fin = ... # compute the finite horizon cost here\n",
    "print(\"Infinite horizon cost with u = K @ x:\", cost_fin)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mpc2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
